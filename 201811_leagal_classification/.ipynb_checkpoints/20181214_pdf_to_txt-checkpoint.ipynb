{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 必要なモジュールの導入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pdfの名前一覧を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['005770_hanrei.pdf', '005861_hanrei.pdf', '005888_hanrei.pdf', '006067_hanrei.pdf', '006124_hanrei.pdf', '006162_hanrei.pdf', '006243_hanrei.pdf', '006290_hanrei.pdf', '007819_hanrei.pdf', '007908_hanrei.pdf', '008002_hanrei.pdf', '008016_hanrei.pdf', '008111_hanrei.pdf', '008113_hanrei.pdf', '008128_hanrei.pdf', '008249_hanrei.pdf', '008470_hanrei.pdf', '008527_hanrei.pdf', '008703_hanrei.pdf', '032890_hanrei.pdf', '033738_hanrei.pdf', '033973_hanrei.pdf', '034130_hanrei.pdf', '034141_hanrei.pdf', '034251_hanrei.pdf', '034540_hanrei.pdf', '034567_hanrei.pdf', '034793_hanrei.pdf', '035340_hanrei.pdf', '036079_hanrei.pdf', '036080_hanrei.pdf', '036984_hanrei.pdf', '037171_hanrei.pdf', '037519_hanrei.pdf', '038078_hanrei.pdf', '038317_hanrei.pdf', '081045_hanrei.pdf', '081555_hanrei.pdf', '081916_hanrei.pdf', '082764_hanrei.pdf', '082984_hanrei.pdf']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "os.chdir('data/pdf')\n",
    "name = glob.glob(\"*\")\n",
    "print(name)\n",
    "os.chdir('..')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取得した名前を利用してpdf⇒txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_0.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_1.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_2.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_3.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_4.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_5.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_6.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_7.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_8.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_9.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_10.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_11.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_12.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_13.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_14.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_15.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_16.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_17.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_18.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_19.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_20.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_21.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_22.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_23.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_24.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_25.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_26.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_27.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_28.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_29.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_30.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_31.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_32.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_33.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_34.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_35.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_36.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_37.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_38.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_39.html\n",
      "test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_40.html\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(name)):\n",
    "    input_path = \"data/pdf/\"+str(name[i])\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    codec = 'z-8'\n",
    "    params = LAParams()\n",
    "\n",
    "    with StringIO() as output:\n",
    "        device = TextConverter(rsrcmgr, output, codec=codec, laparams=params)\n",
    "        with open(input_path, 'rb') as input:\n",
    "            interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "            for page in PDFPage.get_pages(input):\n",
    "                interpreter.process_page(page)\n",
    "                #print(output.getvalue())\n",
    "                text = output.getvalue()\n",
    "        device.close()\n",
    "    #テキスト成形\n",
    "    # (罪となるべき事実）を検索\n",
    "    #index1 = text.find(\"（罪となるべき事実）\")\n",
    "    # （各犯行に至る経緯及び罪となるべき事実）\n",
    "    #index2 = text.find(\"（各犯行に至る経緯及び罪となるべき事実）\")\n",
    "    # （犯罪事実）\n",
    "    #index3 = text.find(\"（犯罪事実）\")\n",
    "    # 罪となるべき事実を検索\n",
    "    #index4 = text.find(\"罪となるべき事実\")\n",
    "    #if (index1 != -1)or(index2 != -1)or(index3 != -1)or(index4 != -1):\n",
    "    #    print(count)\n",
    "    \n",
    "    # 漢数字を削除\n",
    "    table = text.maketrans({\n",
    "        '一': '', #左が置換したい文字、右が新しい文字。\n",
    "        '二': '', #左が置換したい文字、右が新しい文字。\n",
    "        '三': '', #左が置換したい文字、右が新しい文字。\n",
    "        '四': '', #左が置換したい文字、右が新しい文字。\n",
    "        '五': '', #左が置換したい文字、右が新しい文字。\n",
    "        '六': '', #左が置換したい文字、右が新しい文字。\n",
    "        '七': '', #左が置換したい文字、右が新しい文字。\n",
    "        '八': '', #左が置換したい文字、右が新しい文字。\n",
    "        '九': '', #左が置換したい文字、右が新しい文字。\n",
    "        '1': '', #左が置換したい文字、右が新しい文字。\n",
    "        '0': '', #左が置換したい文字、右が新しい文字。\n",
    "        '2': '', #左が置換したい文字、右が新しい文字。\n",
    "        '3': '', #左が置換したい文字、右が新しい文字。\n",
    "        '4': '', #左が置換したい文字、右が新しい文字。\n",
    "        '5': '', #左が置換したい文字、右が新しい文字。\n",
    "        '6': '', #左が置換したい文字、右が新しい文字。\n",
    "        '7': '', #左が置換したい文字、右が新しい文字。\n",
    "        '8': '', #左が置換したい文字、右が新しい文字。\n",
    "        '9': '', #左が置換したい文字、右が新しい文字。\n",
    "        '０': '', #左が置換したい文字、右が新しい文字。\n",
    "        '１': '', #左が置換したい文字、右が新しい文字。\n",
    "        '２': '', #左が置換したい文字、右が新しい文字。\n",
    "        '３': '', #左が置換したい文字、右が新しい文字。\n",
    "        '４': '', #左が置換したい文字、右が新しい文字。\n",
    "        '５': '', #左が置換したい文字、右が新しい文字。\n",
    "        '６': '', #左が置換したい文字、右が新しい文字。\n",
    "        '７': '', #左が置換したい文字、右が新しい文字。\n",
    "        '８': '', #左が置換したい文字、右が新しい文字。\n",
    "        '９': '', #左が置換したい文字、右が新しい文字。\n",
    "        '〇': '', #左が置換したい文字、右が新しい文字。\n",
    "        '、': '', #左が置換したい文字、右が新しい文字。\n",
    "        'ころ': '', #左が置換したい文字、右が新しい文字。\n",
    "    })\n",
    "    text = text.translate(table)\n",
    "    # アルファベットを置換\n",
    "    text = re.sub(r'[a-z]+', \"\", text)\n",
    "    text = re.sub(r'[A-Z]+', \"\", text)\n",
    "    text = re.sub(r'[Ａ-Ｂ]+', \"\", text)\n",
    "    # 証拠の標目\n",
    "    text_ = text.split(\"証拠の標目\")\n",
    "    \n",
    "    \n",
    "    #\n",
    "    path_w = \"test_tfidf/tfidf_with_sklearn/fetched_pages/死刑_\"+str(i)+\".html\"\n",
    "    with open(path_w, mode='w',encoding=\"utf-8\") as f:\n",
    "        f.write(text_[0])\n",
    "        print(path_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 頻度抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要なモジュールを導入 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import re\n",
    "import xlrd\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(replaced_text):\n",
    "    \"\"\"\n",
    "    \\S+ matches all non-whitespace characters (the end of the url)\n",
    "    :param html_text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    replaced_text = re.sub(r'http\\S+', '', replaced_text)\n",
    "    #replaced_text = '\\n'.join(s.strip() for s in replaced_text.splitlines()[2:] if s != '')  # skip header by [2:]\n",
    "    replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
    "    replaced_text = re.sub(r'　', ' ', replaced_text)  # 全角空白の除去\n",
    "    replaced_text = re.sub(r'<', ' ', replaced_text)  # 全角空白の除去\n",
    "    replaced_text = re.sub(r'>', ' ', replaced_text)  # 全角空白の除去\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['005770_hanrei.txt', '005861_hanrei.txt', '005888_hanrei.txt', '006067_hanrei.txt', '006124_hanrei.txt', '006162_hanrei.txt', '006243_hanrei.txt', '006290_hanrei.txt', '007819_hanrei.txt', '007908_hanrei.txt', '008002_hanrei.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "os.chdir('data/txt_clean')\n",
    "name = glob.glob(\"*\")\n",
    "print(name)\n",
    "os.chdir('..')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# coding: UTF-8\n",
    "txt_clean = []\n",
    "os.chdir('data/txt_clean')\n",
    "for i in range(len(name)):\n",
    "    f = open(str(name[i]))\n",
    "    txt_clean.append(f.read())  # ファイル終端まで全て読んだデータを返す\n",
    "    f.close()\n",
    "os.chdir('..')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 頻度抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for i in range(len(name)):\n",
    "        data_all = [] #テキストファイルのまとめ先\n",
    "        each_data = [] #語彙の格納先\n",
    "        t = Tokenizer() #形態素解析用のモジュール\n",
    "        pure_text = clean_text(txt_clean[i])\n",
    "        tokens = t.tokenize(pure_text)\n",
    "        for token in tokens:\n",
    "            partOfSpeech = token.part_of_speech.split(',')[0]\n",
    "            # 今回抽出するのは名詞だけとします。（もちろん他の品詞を追加、変更、除外可能です。）\n",
    "            if partOfSpeech == u'名詞':\n",
    "                each_data.append(token.surface) # token.surfaceは表層形(語彙)です。詳しくはこちら...http://ailaby.com/janome/\n",
    "            # すべての形態素を含ませたいのであればif構文を外し、each_data.append(token.surface)のみ記載してください。\n",
    "        data_all.append(each_data)\n",
    "        each_data = []\n",
    "        #すべての語彙を同じ配列に格納\n",
    "        chain_data = list(chain.from_iterable(data_all))\n",
    "        c = Counter(chain_data)\n",
    "\n",
    "        result_ranking = c.most_common(100) # 出現頻度100位までを変数に格納\n",
    "        # 語彙出現ランキングを記述するエクセルを作成（パスは上記参考に適当にいれてください）\n",
    "        result_book = xlsxwriter.Workbook(\"data/txt_clean_words/\"+str(name[i])+\".xlsx\")\n",
    "        # resultという名前のシートを作ります\n",
    "        result_sheet = result_book.add_worksheet('result')\n",
    "        for row in range(len(result_ranking)):\n",
    "            for i in range(len(result_ranking[row])):\n",
    "                result_sheet.write(row, i, result_ranking[row][i])\n",
    "        # エクセルを保存\n",
    "        result_book.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
